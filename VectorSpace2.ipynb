{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOiLws64dLUjtQrJkk0hOwl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sidplex/College/blob/main/VectorSpace2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import math\n",
        "import re\n",
        "import sys\n",
        "import string\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "from collections import defaultdict\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "STOPWORDS = set(stopwords.words(\"english\"))\n",
        "document_filenames = dict()\n",
        "N = 0\n",
        "vocabulary = set()\n",
        "postings = defaultdict(dict)\n",
        "document_frequency = defaultdict(int)\n",
        "length = defaultdict(float)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ieIe6B8KeLE",
        "outputId": "c4b729bd-6c7f-497c-e9b5-5ceec5364724"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from  google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4ECKmMZMMVC",
        "outputId": "ac46c242-ce21-4552-f869-773cef03feba"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents = glob.glob(\"/content/drive/MyDrive/Corpus2/*\")\n",
        "def readcorpus():\n",
        "    global document_filenames, N\n",
        "    N = len(documents)\n",
        "    document_filenames = dict(zip(range(N), documents))"
      ],
      "metadata": {
        "id": "2v7mTcJGKYJa"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(document):\n",
        "    terms = word_tokenize(document)\n",
        "    terms = [term.lower() for term in terms if term not in STOPWORDS]\n",
        "    return terms"
      ],
      "metadata": {
        "id": "SXQG9FGVKlZ0"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_punct(text):\n",
        "    text = \"\".join([char for char in text if char not in string.punctuation])\n",
        "    text = re.sub('[0-9]+', '', text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "VK5NX10tK7nx"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_digits(text):\n",
        "    regex = re.compile(r\"\\d\")\n",
        "    return re.sub(regex, \"\", text)"
      ],
      "metadata": {
        "id": "VGqT0xMMK-P-"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def terms_posting():\n",
        "    global vocabulary, postings\n",
        "    for id in document_filenames:\n",
        "        with open(document_filenames[id], \"r\") as f:\n",
        "            document = f.read()\n",
        "        document = remove_punct(document)\n",
        "        document = remove_digits(document)\n",
        "        terms = tokenize(document)\n",
        "        unique_terms = set(terms)\n",
        "        vocabulary = vocabulary.union(unique_terms)\n",
        "        for term in unique_terms:\n",
        "            postings[term][id] = terms.count(term)"
      ],
      "metadata": {
        "id": "w7_kDUPGKixZ"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def document_frequencies():\n",
        "    global document_frequency\n",
        "    for term in vocabulary:\n",
        "        document_frequency[term] = len(postings[term])\n",
        "    # print(document_frequency)"
      ],
      "metadata": {
        "id": "xzw1GdVeKl6O"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def document_lengths():\n",
        "    global length\n",
        "    for id in document_filenames:\n",
        "        l = 0\n",
        "        for term in vocabulary:\n",
        "            l += term_frequency(term, id) ** 2\n",
        "        length[id] = math.sqrt(l)\n",
        "    # print(length)"
      ],
      "metadata": {
        "id": "IoHB6-eFKoxd"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def term_frequency(term, id):\n",
        "    if id in postings[term]:\n",
        "        return postings[term][id]\n",
        "    else:\n",
        "        return 0.0"
      ],
      "metadata": {
        "id": "9o0mBotkKrZK"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inverse_document_frequency(term):\n",
        "    if term in vocabulary:\n",
        "        return math.log(N / document_frequency[term], 2)\n",
        "    else:\n",
        "        return 0.0"
      ],
      "metadata": {
        "id": "NXLoj-Z7Kt_O"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def similarity(query, id):\n",
        "    similarity = 0.0\n",
        "    for term in query:\n",
        "        if term in vocabulary:\n",
        "            similarity += term_frequency(term, id) * inverse_document_frequency(term)\n",
        "    similarity = similarity / length[id]\n",
        "    return similarity"
      ],
      "metadata": {
        "id": "cFKUbVElK46b"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def finalscores():\n",
        "    query = tokenize(\"Developing your Zomato business account and profile is a great way to boost your restaurantâ€™s online reputation\")\n",
        "    scores = sorted(\n",
        "        [(id, similarity(query, id)) for id in range(N)],\n",
        "        key=lambda x: x[1],\n",
        "        reverse=True,\n",
        "    )\n",
        "    return scores"
      ],
      "metadata": {
        "id": "meaufrn-Kz60"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_scores(scores):\n",
        "    print(\"-\" * 42)\n",
        "    print(\"| %s | %s |\" % (\"Score\", \"Document\"))\n",
        "    print(\"-\" * 42)\n",
        "    for (id, score) in scores:\n",
        "        if score != 0.0:\n",
        "            print(\"| %s | %s |\" % (str(score)[:5], document_filenames[id]))\n",
        "    print(\"-\" * 42, end=\"\\n\\n\")"
      ],
      "metadata": {
        "id": "etKWSlgjKwhi"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    readcorpus()\n",
        "    terms_posting()\n",
        "    document_frequencies()\n",
        "    document_lengths()\n",
        "    scores = finalscores()\n",
        "    # print(terms_posting())\n",
        "    # print(document_frequencies())\n",
        "    # print(document_lengths())\n",
        "    print_scores(scores)\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNU6dK52LBX0",
        "outputId": "87d65cea-739e-4983-93c1-9fc4dc12bd81"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------\n",
            "| Score | Document |\n",
            "------------------------------------------\n",
            "| 4.858 | /content/drive/MyDrive/Corpus2/zomato.txt |\n",
            "| 1.617 | /content/drive/MyDrive/Corpus2/swiggy.txt |\n",
            "| 0.936 | /content/drive/MyDrive/Corpus2/instagram.txt |\n",
            "| 0.643 | /content/drive/MyDrive/Corpus2/messenger.txt |\n",
            "| 0.608 | /content/drive/MyDrive/Corpus2/flipkart.txt |\n",
            "| 0.589 | /content/drive/MyDrive/Corpus2/reddit.txt |\n",
            "| 0.385 | /content/drive/MyDrive/Corpus2/nike.txt |\n",
            "| 0.339 | /content/drive/MyDrive/Corpus2/shakespeare.txt |\n",
            "| 0.336 | /content/drive/MyDrive/Corpus2/Discord.txt |\n",
            "| 0.310 | /content/drive/MyDrive/Corpus2/paypal.txt |\n",
            "| 0.309 | /content/drive/MyDrive/Corpus2/Amazon.txt |\n",
            "| 0.283 | /content/drive/MyDrive/Corpus2/sony.txt |\n",
            "| 0.274 | /content/drive/MyDrive/Corpus2/reliance.txt |\n",
            "| 0.242 | /content/drive/MyDrive/Corpus2/skype.txt |\n",
            "| 0.234 | /content/drive/MyDrive/Corpus2/steam.txt |\n",
            "| 0.225 | /content/drive/MyDrive/Corpus2/samsung.txt |\n",
            "| 0.207 | /content/drive/MyDrive/Corpus2/whatsapp.txt |\n",
            "| 0.206 | /content/drive/MyDrive/Corpus2/youtube.txt |\n",
            "| 0.202 | /content/drive/MyDrive/Corpus2/volkswagen.txt |\n",
            "| 0.192 | /content/drive/MyDrive/Corpus2/motorola.txt |\n",
            "| 0.191 | /content/drive/MyDrive/Corpus2/telegram.txt |\n",
            "| 0.186 | /content/drive/MyDrive/Corpus2/HP.txt |\n",
            "| 0.174 | /content/drive/MyDrive/Corpus2/levis.txt |\n",
            "| 0.162 | /content/drive/MyDrive/Corpus2/puma.txt |\n",
            "| 0.151 | /content/drive/MyDrive/Corpus2/Uber.txt |\n",
            "| 0.150 | /content/drive/MyDrive/Corpus2/yahoo.txt |\n",
            "| 0.139 | /content/drive/MyDrive/Corpus2/microsoft.txt |\n",
            "| 0.136 | /content/drive/MyDrive/Corpus2/Lenovo.txt |\n",
            "| 0.116 | /content/drive/MyDrive/Corpus2/spotify.txt |\n",
            "| 0.115 | /content/drive/MyDrive/Corpus2/canva.txt |\n",
            "| 0.108 | /content/drive/MyDrive/Corpus2/apple.txt |\n",
            "| 0.108 | /content/drive/MyDrive/Corpus2/Ola.txt |\n",
            "| 0.099 | /content/drive/MyDrive/Corpus2/google.txt |\n",
            "| 0.095 | /content/drive/MyDrive/Corpus2/Dell.txt |\n",
            "| 0.092 | /content/drive/MyDrive/Corpus2/Adobe.txt |\n",
            "| 0.071 | /content/drive/MyDrive/Corpus2/bing.txt |\n",
            "| 0.071 | /content/drive/MyDrive/Corpus2/nokia.txt |\n",
            "| 0.070 | /content/drive/MyDrive/Corpus2/huawei.txt |\n",
            "| 0.054 | /content/drive/MyDrive/Corpus2/operating.txt |\n",
            "| 0.031 | /content/drive/MyDrive/Corpus2/Binance.txt |\n",
            "| 0.014 | /content/drive/MyDrive/Corpus2/blackberry.txt |\n",
            "------------------------------------------\n",
            "\n"
          ]
        }
      ]
    }
  ]
}